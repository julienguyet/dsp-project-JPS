{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>50605.27</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>13740.12</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>39954.04</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>32229.38</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  Dept        Date  Weekly_Sales  Temperature  Fuel_Price  MarkDown1  \\\n",
       "0      1     1  2010-02-05      24924.50        42.31       2.572        NaN   \n",
       "1      1     2  2010-02-05      50605.27        42.31       2.572        NaN   \n",
       "2      1     3  2010-02-05      13740.12        42.31       2.572        NaN   \n",
       "3      1     4  2010-02-05      39954.04        42.31       2.572        NaN   \n",
       "4      1     5  2010-02-05      32229.38        42.31       2.572        NaN   \n",
       "\n",
       "   MarkDown2  MarkDown3  MarkDown4  MarkDown5         CPI  Unemployment  \\\n",
       "0        NaN        NaN        NaN        NaN  211.096358         8.106   \n",
       "1        NaN        NaN        NaN        NaN  211.096358         8.106   \n",
       "2        NaN        NaN        NaN        NaN  211.096358         8.106   \n",
       "3        NaN        NaN        NaN        NaN  211.096358         8.106   \n",
       "4        NaN        NaN        NaN        NaN  211.096358         8.106   \n",
       "\n",
       "   IsHoliday Type    Size  \n",
       "0      False    A  151315  \n",
       "1      False    A  151315  \n",
       "2      False    A  151315  \n",
       "3      False    A  151315  \n",
       "4      False    A  151315  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/full_data/walmart_sales.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store             int64\n",
       "Dept              int64\n",
       "Date             object\n",
       "Weekly_Sales    float64\n",
       "Temperature     float64\n",
       "Fuel_Price      float64\n",
       "MarkDown1       float64\n",
       "MarkDown2       float64\n",
       "MarkDown3       float64\n",
       "MarkDown4       float64\n",
       "MarkDown5       float64\n",
       "CPI             float64\n",
       "Unemployment    float64\n",
       "IsHoliday          bool\n",
       "Type             object\n",
       "Size              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_file(input_file: str, output_dir: str, num_parts: int) -> None:\n",
    "    with open(input_file, 'r') as f:\n",
    "        column_titles = f.readline().strip().split(',')\n",
    "        content = f.readlines()[1:] \n",
    "        file_size = len(content)\n",
    "        part_size = file_size // num_parts\n",
    "\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        for i in range(num_parts):\n",
    "            start_index = i * part_size\n",
    "            end_index = start_index + part_size\n",
    "            if i == num_parts - 1:\n",
    "                end_index = file_size\n",
    "            \n",
    "            part_content = content[start_index:end_index]\n",
    "            part_filename = os.path.join(output_dir, f'test_part_{i + 1}.csv')\n",
    "            with open(part_filename, 'w', newline='') as part_file:\n",
    "                part_file.write(','.join(column_titles[:3] + column_titles[4:]) + '\\n')\n",
    "                \n",
    "                for line in part_content:\n",
    "                    values = line.strip().split(',')\n",
    "                    corrected_values = values[:3] + values[4:]\n",
    "                    part_file.write(','.join(corrected_values) + '\\n')\n",
    "\n",
    "    print(f'{num_parts} parts created successfully.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 parts created successfully.\n"
     ]
    }
   ],
   "source": [
    "split_file(input_file='../data/full_data/walmart_sales.csv', output_dir='../airflow/dags/raw_data', num_parts=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_data(data_directory: str, output_dir: str, ratio: float) -> None:\n",
    "    \n",
    "    # issue 1: shuffle columns\n",
    "    for i in range(20):\n",
    "        random_file = np.random.choice(os.listdir(data_directory))\n",
    "        file_path = os.path.join(data_directory, random_file)\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        column_names = df.columns.tolist()\n",
    "        shuffled_column_names = np.random.permutation(column_names)\n",
    "        shuffled_df = df[shuffled_column_names]\n",
    "        shuffled_df.to_csv(f'{output_dir}/shuffled_partition{i}.csv', index=False)\n",
    "        print(\"Shuffled dataset succesfully and saved as csv\")\n",
    "\n",
    "    i = 0\n",
    "    for file in os.listdir(data_directory):\n",
    "        file_path = os.path.join(data_directory, file)\n",
    "        \n",
    "        if not file.endswith('.csv'):\n",
    "            continue\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        gibberish = [\"Monday is sunny\", \"no sales today\", \"economic crash\", \" \", \"no work today\"]\n",
    "        random_number = np.random.randint(len(df), size=len(df))\n",
    "        negative_numbers = np.arange(-100, 0)\n",
    "        cells_to_delete = int(df.size * ratio)\n",
    "        cells_to_delete_indices = np.random.choice(df.size, cells_to_delete, replace=False)\n",
    "\n",
    "        # issue 2: missing data\n",
    "        for cell_index in range(cells_to_delete):\n",
    "            random_cell_index = cells_to_delete_indices[cell_index]\n",
    "            row_index, col_index = np.unravel_index(random_cell_index, df.shape)\n",
    "            column_name = np.random.choice(df.columns)\n",
    "            df.at[row_index, column_name] = np.nan\n",
    "        \n",
    "        # issue 3: replace text with integer\n",
    "        column_name = 'IsHoliday'\n",
    "        cells_to_change_to_integer = np.random.choice(df.index, cells_to_delete // 2, replace=False)\n",
    "        df.loc[cells_to_change_to_integer, column_name] = np.random.choice(random_number)\n",
    "        \n",
    "        # issue 4: replace int or float with text\n",
    "        column_name = 'CPI'\n",
    "        cells_to_change_to_integer = np.random.choice(df.index, cells_to_delete // 2, replace=False)\n",
    "        df.loc[cells_to_change_to_integer, column_name] = np.random.choice(gibberish)\n",
    "\n",
    "        # issue 5: unexpected value in a column\n",
    "        column_name = 'Type'\n",
    "        cells_to_change_to_integer = np.random.choice(df.index, cells_to_delete // 2, replace=False)\n",
    "        df.loc[cells_to_change_to_integer, column_name] = np.random.choice(gibberish)\n",
    "\n",
    "        # issue 6: negative number in a column:\n",
    "        column_name = 'Size'\n",
    "        cells_to_change_to_integer = np.random.choice(df.index, cells_to_delete // 2, replace=False)\n",
    "        df.loc[cells_to_change_to_integer, column_name] = np.random.choice(negative_numbers)\n",
    "\n",
    "        # Save\n",
    "        df.to_csv(f\"{output_dir}/partition_{i}.csv\", encoding=\"utf-8\", index=False)\n",
    "        print(f\"CSV file 'partition_{i}.csv' has been successfully generated\")\n",
    "        i += 1\n",
    "    \n",
    "    # issue 7: missing column\n",
    "    for i in range(20):\n",
    "        random_file = np.random.choice(os.listdir(data_directory))\n",
    "        file_path = os.path.join(data_directory, random_file)\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "        column_names = df.columns.tolist()\n",
    "        random_column = np.random.choice(column_names)\n",
    "        df_missing_column = df.drop(columns=random_column)\n",
    "        df_missing_column.to_csv(f'{output_dir}/partition_short{i}.csv', index=False)\n",
    "        print(\"Dropped column succesfully and saved dataset as csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled dataset succesfully and saved as csv\n",
      "Shuffled dataset succesfully and saved as csv\n",
      "Shuffled dataset succesfully and saved as csv\n",
      "Shuffled dataset succesfully and saved as csv\n",
      "Shuffled dataset succesfully and saved as csv\n",
      "Shuffled dataset succesfully and saved as csv\n",
      "Shuffled dataset succesfully and saved as csv\n",
      "Shuffled dataset succesfully and saved as csv\n",
      "Shuffled dataset succesfully and saved as csv\n",
      "Shuffled dataset succesfully and saved as csv\n",
      "Shuffled dataset succesfully and saved as csv\n",
      "Shuffled dataset succesfully and saved as csv\n",
      "Shuffled dataset succesfully and saved as csv\n",
      "Shuffled dataset succesfully and saved as csv\n",
      "Shuffled dataset succesfully and saved as csv\n",
      "Shuffled dataset succesfully and saved as csv\n",
      "Shuffled dataset succesfully and saved as csv\n",
      "Shuffled dataset succesfully and saved as csv\n",
      "Shuffled dataset succesfully and saved as csv\n",
      "Shuffled dataset succesfully and saved as csv\n",
      "CSV file 'partition_0.csv' has been successfully generated\n",
      "CSV file 'partition_1.csv' has been successfully generated\n",
      "CSV file 'partition_2.csv' has been successfully generated\n",
      "CSV file 'partition_3.csv' has been successfully generated\n",
      "CSV file 'partition_4.csv' has been successfully generated\n",
      "CSV file 'partition_5.csv' has been successfully generated\n",
      "CSV file 'partition_6.csv' has been successfully generated\n",
      "CSV file 'partition_7.csv' has been successfully generated\n",
      "CSV file 'partition_8.csv' has been successfully generated\n",
      "CSV file 'partition_9.csv' has been successfully generated\n",
      "CSV file 'partition_10.csv' has been successfully generated\n",
      "CSV file 'partition_11.csv' has been successfully generated\n",
      "CSV file 'partition_12.csv' has been successfully generated\n",
      "CSV file 'partition_13.csv' has been successfully generated\n",
      "CSV file 'partition_14.csv' has been successfully generated\n",
      "CSV file 'partition_15.csv' has been successfully generated\n",
      "CSV file 'partition_16.csv' has been successfully generated\n",
      "CSV file 'partition_17.csv' has been successfully generated\n",
      "CSV file 'partition_18.csv' has been successfully generated\n",
      "CSV file 'partition_19.csv' has been successfully generated\n",
      "CSV file 'partition_20.csv' has been successfully generated\n",
      "CSV file 'partition_21.csv' has been successfully generated\n",
      "CSV file 'partition_22.csv' has been successfully generated\n",
      "CSV file 'partition_23.csv' has been successfully generated\n",
      "CSV file 'partition_24.csv' has been successfully generated\n",
      "CSV file 'partition_25.csv' has been successfully generated\n",
      "CSV file 'partition_26.csv' has been successfully generated\n",
      "CSV file 'partition_27.csv' has been successfully generated\n",
      "CSV file 'partition_28.csv' has been successfully generated\n",
      "CSV file 'partition_29.csv' has been successfully generated\n",
      "CSV file 'partition_30.csv' has been successfully generated\n",
      "CSV file 'partition_31.csv' has been successfully generated\n",
      "CSV file 'partition_32.csv' has been successfully generated\n",
      "CSV file 'partition_33.csv' has been successfully generated\n",
      "CSV file 'partition_34.csv' has been successfully generated\n",
      "CSV file 'partition_35.csv' has been successfully generated\n",
      "CSV file 'partition_36.csv' has been successfully generated\n",
      "CSV file 'partition_37.csv' has been successfully generated\n",
      "CSV file 'partition_38.csv' has been successfully generated\n",
      "CSV file 'partition_39.csv' has been successfully generated\n",
      "CSV file 'partition_40.csv' has been successfully generated\n",
      "CSV file 'partition_41.csv' has been successfully generated\n",
      "CSV file 'partition_42.csv' has been successfully generated\n",
      "CSV file 'partition_43.csv' has been successfully generated\n",
      "CSV file 'partition_44.csv' has been successfully generated\n",
      "CSV file 'partition_45.csv' has been successfully generated\n",
      "CSV file 'partition_46.csv' has been successfully generated\n",
      "CSV file 'partition_47.csv' has been successfully generated\n",
      "CSV file 'partition_48.csv' has been successfully generated\n",
      "CSV file 'partition_49.csv' has been successfully generated\n",
      "CSV file 'partition_50.csv' has been successfully generated\n",
      "CSV file 'partition_51.csv' has been successfully generated\n",
      "CSV file 'partition_52.csv' has been successfully generated\n",
      "CSV file 'partition_53.csv' has been successfully generated\n",
      "CSV file 'partition_54.csv' has been successfully generated\n",
      "CSV file 'partition_55.csv' has been successfully generated\n",
      "CSV file 'partition_56.csv' has been successfully generated\n",
      "CSV file 'partition_57.csv' has been successfully generated\n",
      "CSV file 'partition_58.csv' has been successfully generated\n",
      "CSV file 'partition_59.csv' has been successfully generated\n",
      "CSV file 'partition_60.csv' has been successfully generated\n",
      "CSV file 'partition_61.csv' has been successfully generated\n",
      "CSV file 'partition_62.csv' has been successfully generated\n",
      "CSV file 'partition_63.csv' has been successfully generated\n",
      "CSV file 'partition_64.csv' has been successfully generated\n",
      "CSV file 'partition_65.csv' has been successfully generated\n",
      "CSV file 'partition_66.csv' has been successfully generated\n",
      "CSV file 'partition_67.csv' has been successfully generated\n",
      "CSV file 'partition_68.csv' has been successfully generated\n",
      "CSV file 'partition_69.csv' has been successfully generated\n",
      "CSV file 'partition_70.csv' has been successfully generated\n",
      "CSV file 'partition_71.csv' has been successfully generated\n",
      "CSV file 'partition_72.csv' has been successfully generated\n",
      "CSV file 'partition_73.csv' has been successfully generated\n",
      "CSV file 'partition_74.csv' has been successfully generated\n",
      "CSV file 'partition_75.csv' has been successfully generated\n",
      "CSV file 'partition_76.csv' has been successfully generated\n",
      "CSV file 'partition_77.csv' has been successfully generated\n",
      "CSV file 'partition_78.csv' has been successfully generated\n",
      "CSV file 'partition_79.csv' has been successfully generated\n",
      "CSV file 'partition_80.csv' has been successfully generated\n",
      "CSV file 'partition_81.csv' has been successfully generated\n",
      "CSV file 'partition_82.csv' has been successfully generated\n",
      "CSV file 'partition_83.csv' has been successfully generated\n",
      "CSV file 'partition_84.csv' has been successfully generated\n",
      "CSV file 'partition_85.csv' has been successfully generated\n",
      "CSV file 'partition_86.csv' has been successfully generated\n",
      "CSV file 'partition_87.csv' has been successfully generated\n",
      "CSV file 'partition_88.csv' has been successfully generated\n",
      "CSV file 'partition_89.csv' has been successfully generated\n",
      "CSV file 'partition_90.csv' has been successfully generated\n",
      "CSV file 'partition_91.csv' has been successfully generated\n",
      "CSV file 'partition_92.csv' has been successfully generated\n",
      "CSV file 'partition_93.csv' has been successfully generated\n",
      "CSV file 'partition_94.csv' has been successfully generated\n",
      "CSV file 'partition_95.csv' has been successfully generated\n",
      "CSV file 'partition_96.csv' has been successfully generated\n",
      "CSV file 'partition_97.csv' has been successfully generated\n",
      "CSV file 'partition_98.csv' has been successfully generated\n",
      "CSV file 'partition_99.csv' has been successfully generated\n",
      "CSV file 'partition_100.csv' has been successfully generated\n",
      "CSV file 'partition_101.csv' has been successfully generated\n",
      "CSV file 'partition_102.csv' has been successfully generated\n",
      "CSV file 'partition_103.csv' has been successfully generated\n",
      "CSV file 'partition_104.csv' has been successfully generated\n",
      "CSV file 'partition_105.csv' has been successfully generated\n",
      "CSV file 'partition_106.csv' has been successfully generated\n",
      "CSV file 'partition_107.csv' has been successfully generated\n",
      "CSV file 'partition_108.csv' has been successfully generated\n",
      "CSV file 'partition_109.csv' has been successfully generated\n",
      "CSV file 'partition_110.csv' has been successfully generated\n",
      "CSV file 'partition_111.csv' has been successfully generated\n",
      "CSV file 'partition_112.csv' has been successfully generated\n",
      "CSV file 'partition_113.csv' has been successfully generated\n",
      "CSV file 'partition_114.csv' has been successfully generated\n",
      "CSV file 'partition_115.csv' has been successfully generated\n",
      "CSV file 'partition_116.csv' has been successfully generated\n",
      "CSV file 'partition_117.csv' has been successfully generated\n",
      "CSV file 'partition_118.csv' has been successfully generated\n",
      "CSV file 'partition_119.csv' has been successfully generated\n",
      "CSV file 'partition_120.csv' has been successfully generated\n",
      "CSV file 'partition_121.csv' has been successfully generated\n",
      "CSV file 'partition_122.csv' has been successfully generated\n",
      "CSV file 'partition_123.csv' has been successfully generated\n",
      "CSV file 'partition_124.csv' has been successfully generated\n",
      "CSV file 'partition_125.csv' has been successfully generated\n",
      "CSV file 'partition_126.csv' has been successfully generated\n",
      "CSV file 'partition_127.csv' has been successfully generated\n",
      "CSV file 'partition_128.csv' has been successfully generated\n",
      "CSV file 'partition_129.csv' has been successfully generated\n",
      "CSV file 'partition_130.csv' has been successfully generated\n",
      "CSV file 'partition_131.csv' has been successfully generated\n",
      "CSV file 'partition_132.csv' has been successfully generated\n",
      "CSV file 'partition_133.csv' has been successfully generated\n",
      "CSV file 'partition_134.csv' has been successfully generated\n",
      "CSV file 'partition_135.csv' has been successfully generated\n",
      "CSV file 'partition_136.csv' has been successfully generated\n",
      "CSV file 'partition_137.csv' has been successfully generated\n",
      "CSV file 'partition_138.csv' has been successfully generated\n",
      "CSV file 'partition_139.csv' has been successfully generated\n",
      "CSV file 'partition_140.csv' has been successfully generated\n",
      "CSV file 'partition_141.csv' has been successfully generated\n",
      "CSV file 'partition_142.csv' has been successfully generated\n",
      "CSV file 'partition_143.csv' has been successfully generated\n",
      "CSV file 'partition_144.csv' has been successfully generated\n",
      "CSV file 'partition_145.csv' has been successfully generated\n",
      "CSV file 'partition_146.csv' has been successfully generated\n",
      "CSV file 'partition_147.csv' has been successfully generated\n",
      "CSV file 'partition_148.csv' has been successfully generated\n",
      "CSV file 'partition_149.csv' has been successfully generated\n",
      "CSV file 'partition_150.csv' has been successfully generated\n",
      "CSV file 'partition_151.csv' has been successfully generated\n",
      "CSV file 'partition_152.csv' has been successfully generated\n",
      "CSV file 'partition_153.csv' has been successfully generated\n",
      "CSV file 'partition_154.csv' has been successfully generated\n",
      "CSV file 'partition_155.csv' has been successfully generated\n",
      "CSV file 'partition_156.csv' has been successfully generated\n",
      "CSV file 'partition_157.csv' has been successfully generated\n",
      "CSV file 'partition_158.csv' has been successfully generated\n",
      "CSV file 'partition_159.csv' has been successfully generated\n",
      "CSV file 'partition_160.csv' has been successfully generated\n",
      "CSV file 'partition_161.csv' has been successfully generated\n",
      "CSV file 'partition_162.csv' has been successfully generated\n",
      "CSV file 'partition_163.csv' has been successfully generated\n",
      "CSV file 'partition_164.csv' has been successfully generated\n",
      "CSV file 'partition_165.csv' has been successfully generated\n",
      "CSV file 'partition_166.csv' has been successfully generated\n",
      "CSV file 'partition_167.csv' has been successfully generated\n",
      "CSV file 'partition_168.csv' has been successfully generated\n",
      "CSV file 'partition_169.csv' has been successfully generated\n",
      "CSV file 'partition_170.csv' has been successfully generated\n",
      "CSV file 'partition_171.csv' has been successfully generated\n",
      "CSV file 'partition_172.csv' has been successfully generated\n",
      "CSV file 'partition_173.csv' has been successfully generated\n",
      "CSV file 'partition_174.csv' has been successfully generated\n",
      "CSV file 'partition_175.csv' has been successfully generated\n",
      "CSV file 'partition_176.csv' has been successfully generated\n",
      "CSV file 'partition_177.csv' has been successfully generated\n",
      "CSV file 'partition_178.csv' has been successfully generated\n",
      "CSV file 'partition_179.csv' has been successfully generated\n",
      "CSV file 'partition_180.csv' has been successfully generated\n",
      "CSV file 'partition_181.csv' has been successfully generated\n",
      "CSV file 'partition_182.csv' has been successfully generated\n",
      "CSV file 'partition_183.csv' has been successfully generated\n",
      "CSV file 'partition_184.csv' has been successfully generated\n",
      "CSV file 'partition_185.csv' has been successfully generated\n",
      "CSV file 'partition_186.csv' has been successfully generated\n",
      "CSV file 'partition_187.csv' has been successfully generated\n",
      "CSV file 'partition_188.csv' has been successfully generated\n",
      "CSV file 'partition_189.csv' has been successfully generated\n",
      "CSV file 'partition_190.csv' has been successfully generated\n",
      "CSV file 'partition_191.csv' has been successfully generated\n",
      "CSV file 'partition_192.csv' has been successfully generated\n",
      "CSV file 'partition_193.csv' has been successfully generated\n",
      "CSV file 'partition_194.csv' has been successfully generated\n",
      "CSV file 'partition_195.csv' has been successfully generated\n",
      "CSV file 'partition_196.csv' has been successfully generated\n",
      "CSV file 'partition_197.csv' has been successfully generated\n",
      "CSV file 'partition_198.csv' has been successfully generated\n",
      "CSV file 'partition_199.csv' has been successfully generated\n",
      "Dropped column succesfully and saved dataset as csv\n",
      "Dropped column succesfully and saved dataset as csv\n",
      "Dropped column succesfully and saved dataset as csv\n",
      "Dropped column succesfully and saved dataset as csv\n",
      "Dropped column succesfully and saved dataset as csv\n",
      "Dropped column succesfully and saved dataset as csv\n",
      "Dropped column succesfully and saved dataset as csv\n",
      "Dropped column succesfully and saved dataset as csv\n",
      "Dropped column succesfully and saved dataset as csv\n",
      "Dropped column succesfully and saved dataset as csv\n",
      "Dropped column succesfully and saved dataset as csv\n",
      "Dropped column succesfully and saved dataset as csv\n",
      "Dropped column succesfully and saved dataset as csv\n",
      "Dropped column succesfully and saved dataset as csv\n",
      "Dropped column succesfully and saved dataset as csv\n",
      "Dropped column succesfully and saved dataset as csv\n",
      "Dropped column succesfully and saved dataset as csv\n",
      "Dropped column succesfully and saved dataset as csv\n",
      "Dropped column succesfully and saved dataset as csv\n",
      "Dropped column succesfully and saved dataset as csv\n"
     ]
    }
   ],
   "source": [
    "delete_data(data_directory='../airflow/dags/raw_data', output_dir='../airflow/dags/corrupted_data', ratio=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
